{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EkpyVgSI5SA"
      },
      "source": [
        "# Acceso de vehículos ResiPark (Detección) - Python 3.11.13"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3GqxTcJL2hM",
        "outputId": "fc6272d2-4d2b-4890-81de-ec946ea99184"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.11.13\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5gqErZgJmDn",
        "outputId": "9ded283d-3eb8-4cdf-d0f3-c46fa28e40a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhNiaTXMqjZp"
      },
      "source": [
        "### Instalar dependencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3bq_3gYlhad",
        "outputId": "23c51c93-7a7f-4331-b208-a57fcb6d1bd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Sep 25 02:15:26 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKLOq4NI9JeS"
      },
      "outputs": [],
      "source": [
        "!pip install timm -q\n",
        "!pip install accelerate -q\n",
        "!pip install einops -q\n",
        "!pip install fastapi uvicorn nest_asyncio\n",
        "!pip install ultralytics opencv-python-headless\n",
        "!apt-get install unzip wget -y\n",
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "!dpkg -i cloudflared-linux-amd64.deb\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiJejRe9lN-Y",
        "outputId": "726a16d9-4235-4d4e-8365-7f6b8862a574"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA está disponible. Usando GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA está disponible. Usando GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"CUDA no está disponible. Usando CPU.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-w-HYE-9N5G"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IV-PkG-j9K9v"
      },
      "outputs": [],
      "source": [
        "!mkdir my_models\n",
        "!mkdir my_models/Florence_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwryZnEDI4Ly"
      },
      "source": [
        "#### Florence Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qXWilYE31av"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoProcessor\n",
        "from transformers import AutoModelForCausalLM, AutoProcessor\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"microsoft/Florence-2-large\",\n",
        "                                             cache_dir=\"/content/my_models/Florence_2\",\n",
        "                                             device_map=\"cuda\",\n",
        "                                             trust_remote_code=True,\n",
        "                                             attn_implementation=\"eager\")\n",
        "\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(\n",
        "    \"microsoft/Florence-2-large\",  # ID del repositorio\n",
        "    token = os.environ[\"HF_TOKEN\"],\n",
        "    trust_remote_code = True,\n",
        "    cache_dir = \"/content/my_models/Florence_2\"  # Se guardará en esta carpeta\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j238rZoSI4Lz"
      },
      "source": [
        "#### App YOLOv11 + OCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YK0xtQVlQJm",
        "outputId": "52fc368a-d1fe-4e01-9dfa-50ca7784739c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "import base64\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from fastapi import FastAPI, UploadFile, File\n",
        "from fastapi.responses import JSONResponse\n",
        "import uvicorn\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import numpy as np\n",
        "import re\n",
        "import logging\n",
        "from typing import List, Dict, Any, Optional, Tuple\n",
        "from contextlib import asynccontextmanager\n",
        "from PIL import Image\n",
        "\n",
        "# Configurar logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Variables globales\n",
        "model_plates = None\n",
        "model_cars = None\n",
        "prompt = '<OCR>'\n",
        "\n",
        "@asynccontextmanager\n",
        "async def lifespan(app: FastAPI):\n",
        "    # Startup\n",
        "    logger.info(\"[INFO] Cargando modelos YOLO...\")\n",
        "    global model_plates, model_cars, prompt\n",
        "\n",
        "\n",
        "    model_plates = YOLO(\"/content/drive/MyDrive/Proyecto/10k_50_plates.pt\") #cambiar direccion de los pesos\n",
        "    model_cars = YOLO('/content/drive/MyDrive/Proyecto/10k_50_cars.pt') # cambiar direccion de los pesos\n",
        "\n",
        "    logger.info(\"[INFO] Cargando Florence-2...\")\n",
        "\n",
        "    logger.info(\"[INFO] API lista para recibir peticiones\")\n",
        "\n",
        "    yield  # Aquí se ejecuta durante la vida de la app\n",
        "\n",
        "app = FastAPI(lifespan=lifespan)\n",
        "\n",
        "def get_detection_zone(img: np.ndarray) -> Tuple[int, int, int, int]:\n",
        "    \"\"\"\n",
        "    Define zona rectangular de detección (ROI)\n",
        "    \"\"\"\n",
        "    h, w, _ = img.shape\n",
        "\n",
        "    # Zona central inferior (donde suelen circular los autos)\n",
        "    width_margin_percent = 0.1\n",
        "    height_start_percent = 0.4\n",
        "    height_end_percent = 0.9\n",
        "\n",
        "    margin_w = int(w * width_margin_percent)\n",
        "    x1 = margin_w\n",
        "    x2 = w - margin_w\n",
        "\n",
        "    y1 = int(h * height_start_percent)\n",
        "    y2 = int(h * height_end_percent)\n",
        "\n",
        "    return x1, y1, x2, y2\n",
        "\n",
        "def boxes_intersect(box1: List[int], box2: List[int]) -> bool:\n",
        "    \"\"\"\n",
        "    Verifica si dos bounding boxes se intersectan (se tocan)\n",
        "\n",
        "    Args:\n",
        "        box1: [x1, y1, x2, y2] del vehículo\n",
        "        box2: [x1, y1, x2, y2] del ROI\n",
        "\n",
        "    Returns:\n",
        "        True si hay intersección, False otherwise\n",
        "    \"\"\"\n",
        "    x1_veh, y1_veh, x2_veh, y2_veh = box1\n",
        "    x1_roi, y1_roi, x2_roi, y2_roi = box2\n",
        "\n",
        "    # Verificar intersección en eje X\n",
        "    intersect_x = not (x2_veh < x1_roi or x1_veh > x2_roi)\n",
        "\n",
        "    # Verificar intersección en eje Y\n",
        "    intersect_y = not (y2_veh < y1_roi or y1_veh > y2_roi)\n",
        "\n",
        "    # Hay intersección si ambos ejes se intersectan\n",
        "    return intersect_x and intersect_y\n",
        "\n",
        "def calculate_intersection_area(box1: List[int], box2: List[int]) -> int:\n",
        "    \"\"\"\n",
        "    Calcula el área de intersección entre dos bounding boxes\n",
        "    \"\"\"\n",
        "    x1_veh, y1_veh, x2_veh, y2_veh = box1\n",
        "    x1_roi, y1_roi, x2_roi, y2_roi = box2\n",
        "\n",
        "    # Coordenadas de la intersección\n",
        "    x1_int = max(x1_veh, x1_roi)\n",
        "    y1_int = max(y1_veh, y1_roi)\n",
        "    x2_int = min(x2_veh, x2_roi)\n",
        "    y2_int = min(y2_veh, y2_roi)\n",
        "\n",
        "    # Calcular área (asegurarse de que no sea negativa)\n",
        "    width = max(0, x2_int - x1_int)\n",
        "    height = max(0, y2_int - y1_int)\n",
        "\n",
        "    return width * height\n",
        "\n",
        "def is_vehicle_in_roi(vehicle_box: List[int], roi_box: List[int], min_intersection: int = 100) -> bool:\n",
        "    \"\"\"\n",
        "    Verifica si un vehículo toca el ROI con al menos un área mínima de intersección\n",
        "\n",
        "    Args:\n",
        "        vehicle_box: [x1, y1, x2, y2] del vehículo\n",
        "        roi_box: [x1, y1, x2, y2] del ROI\n",
        "        min_intersection: área mínima de intersección en píxeles (default: 100)\n",
        "\n",
        "    Returns:\n",
        "        True si el vehículo toca el ROI con al menos el área mínima\n",
        "    \"\"\"\n",
        "    if not boxes_intersect(vehicle_box, roi_box):\n",
        "        return False\n",
        "\n",
        "    # Calcular área de intersección\n",
        "    intersection_area = calculate_intersection_area(vehicle_box, roi_box)\n",
        "\n",
        "    # Verificar que la intersección sea significativa (evitar toques de 1 píxel)\n",
        "    return intersection_area >= min_intersection\n",
        "\n",
        "\n",
        "def prueba_ocr(texts):\n",
        "\n",
        "  texts = texts.upper()\n",
        "  texts = re.sub(r\" +\", \"\", texts)\n",
        "  texts = texts.strip('\\n').split()\n",
        "\n",
        "  candidates = []\n",
        "\n",
        "  for t in texts:\n",
        "\n",
        "        # limpiar todo lo que no sea letras o números\n",
        "        t = re.sub(r\"[^A-Z0-9]\", \"\", t)\n",
        "\n",
        "        # validaciones básicas\n",
        "        if len(t) < 5 or len(t) > 8:  # ahora permitimos 5–8\n",
        "            continue\n",
        "        if t.isalpha() or t.isdigit():  # solo letras o solo números\n",
        "            continue\n",
        "\n",
        "        # regex básica: mezcla de letras y números\n",
        "        if not re.match(r\"^(?=.*[A-Z])(?=.*[0-9])[A-Z0-9]+$\", t):\n",
        "            continue\n",
        "\n",
        "        candidates.append(t)\n",
        "\n",
        "  if not candidates:\n",
        "      return None\n",
        "\n",
        "    # heurística: preferimos el string más largo (más completo)\n",
        "  plate = max(candidates, key=len)\n",
        "\n",
        "  return plate\n",
        "\n",
        "\n",
        "def florence_ocr(prompt, image_):\n",
        "  '''\n",
        "  Modelo Florence-2\n",
        "  Transcripcion y llamado de funcion para limpiar\n",
        "  '''\n",
        "\n",
        "  if isinstance(image_, np.ndarray):\n",
        "      image = Image.fromarray(image_).convert(\"RGB\")\n",
        "\n",
        "  else:\n",
        "      image = Image.open(image_).convert(\"RGB\")\n",
        "\n",
        "  inputs = processor(text=prompt, images=image, return_tensors=\"pt\").to(\"cuda:0\")\n",
        "\n",
        "  generated_ids = model.generate(\n",
        "      input_ids=inputs[\"input_ids\"],\n",
        "      pixel_values=inputs[\"pixel_values\"],\n",
        "      max_new_tokens=32,\n",
        "  \t  early_stopping=True,\n",
        "  \t  do_sample=False,\n",
        "  \t  num_beams=5\n",
        "    )\n",
        "\n",
        "  generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
        "  parsed_answer = processor.post_process_generation(generated_text, task=prompt, image_size=(image.width, image.height))\n",
        "\n",
        "  return prueba_ocr(parsed_answer['<OCR>'])\n",
        "\n",
        "\n",
        "@app.post(\"/predict\")\n",
        "async def predict(file: UploadFile = File(...), min_intersection: int = 100):\n",
        "    try:\n",
        "        contents = await file.read()\n",
        "        npimg = np.frombuffer(contents, np.uint8)\n",
        "        img = cv2.imdecode(npimg, cv2.IMREAD_COLOR)\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        detections = []\n",
        "        roi_zone = get_detection_zone(img_rgb) # Zona de detección\n",
        "\n",
        "        vehicle_results = model_cars(img_rgb, conf=0.7, verbose=False)\n",
        "        vehicle_boxes = vehicle_results[0].boxes\n",
        "\n",
        "        if vehicle_boxes is None:\n",
        "            return JSONResponse(content={\"detections\": []})\n",
        "\n",
        "        boxes = vehicle_boxes.xyxy.cpu().numpy()\n",
        "        confs = vehicle_boxes.conf.cpu().numpy()\n",
        "        class_ids = vehicle_boxes.cls.cpu().numpy().astype(int)\n",
        "\n",
        "        for i, box in enumerate(boxes):\n",
        "            x1, y1, x2, y2 = map(int, box[:4])\n",
        "            vehicle_box = [x1, y1, x2, y2]\n",
        "\n",
        "            if not is_vehicle_in_roi(vehicle_box, roi_zone, min_intersection):\n",
        "                continue\n",
        "\n",
        "            vehicle_crop = img_rgb[y1:y2, x1:x2]\n",
        "            if vehicle_crop.size == 0:\n",
        "                continue\n",
        "\n",
        "            # OPTIMIZACIÓN: Placas con menor resolución\n",
        "            plate_results = model_plates(vehicle_crop, conf=0.7, verbose=False)\n",
        "            plate_boxes = plate_results[0].boxes\n",
        "\n",
        "            if plate_boxes is None:\n",
        "                continue\n",
        "\n",
        "            plate_confs = plate_boxes.conf.cpu().numpy()\n",
        "\n",
        "            # VERIFICAR QUE HAY CONFIANZAS VÁLIDAS\n",
        "            if plate_confs.size == 0 or len(plate_confs) == 0:\n",
        "                continue  # No hay valores de confianza\n",
        "\n",
        "            best_plate_idx = np.argmax(plate_confs)\n",
        "            plate_box = plate_boxes.xyxy.cpu().numpy()[best_plate_idx]\n",
        "            px1, py1, px2, py2 = map(int, plate_box[:4])\n",
        "\n",
        "            # Padding\n",
        "            h, w, _ = vehicle_crop.shape\n",
        "            pad = 0.08\n",
        "            x1_pad = max(0, int(px1 - (px2 - px1) * pad))\n",
        "            y1_pad = max(0, int(py1 - (py2 - py1) * pad))\n",
        "            x2_pad = min(w, int(px2 + (px2 - px1) * pad))\n",
        "            y2_pad = min(h, int(py2 + (py2 - py1) * pad))\n",
        "\n",
        "\n",
        "            plate_crop = vehicle_crop[y1_pad:y2_pad, x1_pad:x2_pad]\n",
        "            if plate_crop.size == 0:\n",
        "                continue\n",
        "\n",
        "            # Florence-2 (OCR)\n",
        "            plate_text = florence_ocr(prompt, plate_crop)\n",
        "\n",
        "            if plate_text == None:\n",
        "                continue\n",
        "\n",
        "            detections.append({\n",
        "                \"vehicle_type\": model_cars.names[class_ids[i]],\n",
        "                \"vehicle_confidence\": round(float(confs[i]), 3),\n",
        "                \"plate_confidence\": round(float(plate_confs[best_plate_idx]), 3),\n",
        "                \"plate_text\": plate_text,\n",
        "            })\n",
        "\n",
        "\n",
        "        return JSONResponse(content={\"detections\": detections})\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error en procesamiento: {str(e)}\")\n",
        "        return JSONResponse(content={\"detections\": []})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqNF-RVCI4Lz"
      },
      "source": [
        "#### Uvicorn server LocalHost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eBpVw9WLlUcS"
      },
      "outputs": [],
      "source": [
        "import threading\n",
        "\n",
        "def run():\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "\n",
        "thread = threading.Thread(target=run, daemon=True)\n",
        "thread.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAJ80dmPI4Lz"
      },
      "source": [
        "#### Tunel CloudFlare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-9D-X6RlXPB",
        "outputId": "e26ee2d5-9308-44d4-e73a-db00ef87a8e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[90m2025-09-25T02:23:37Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2025-09-25T02:23:37Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Application startup complete.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[90m2025-09-25T02:23:40Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-09-25T02:23:40Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2025-09-25T02:23:40Z\u001b[0m \u001b[32mINF\u001b[0m |  https://characterized-consciousness-functioning-effectively.trycloudflare.com             |\n",
            "\u001b[90m2025-09-25T02:23:40Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-09-25T02:23:40Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "\u001b[90m2025-09-25T02:23:40Z\u001b[0m \u001b[32mINF\u001b[0m Version 2025.9.1 (Checksum 3dc1dc4252eae3c691861f926e2b8640063a2ce534b07b7a3f4ec2de439ecfe3)\n",
            "\u001b[90m2025-09-25T02:23:40Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.24.4, GoArch: amd64\n",
            "\u001b[90m2025-09-25T02:23:40Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 no-autoupdate:true protocol:quic url:http://127.0.0.1:8000]\n",
            "\u001b[90m2025-09-25T02:23:40Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update if installed by a package manager.\n",
            "\u001b[90m2025-09-25T02:23:40Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: c2b68d14-4dda-4345-a00b-38484e87c165\n",
            "\u001b[90m2025-09-25T02:23:40Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
            "\u001b[90m2025-09-25T02:23:40Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.30.0.2 as source for IPv4\n",
            "\u001b[90m2025-09-25T02:23:40Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use fe80::c75:f9ff:fe41:b838 in zone eth0 as source for IPv6\n",
            "\u001b[90m2025-09-25T02:23:40Z\u001b[0m \u001b[31mWRN\u001b[0m The user running cloudflared process has a GID (group ID) that is not within ping_group_range. You might need to add that user to a group within that range, or instead update the range to encompass a group the user is already in by modifying /proc/sys/net/ipv4/ping_group_range. Otherwise cloudflared will not be able to ping this network \u001b[31merror=\u001b[0m\u001b[31m\"Group ID 0 is not between ping group 1 to 0\"\u001b[0m\n",
            "\u001b[90m2025-09-25T02:23:40Z\u001b[0m \u001b[31mWRN\u001b[0m ICMP proxy feature is disabled \u001b[31merror=\u001b[0m\u001b[31m\"cannot create ICMPv4 proxy: Group ID 0 is not between ping group 1 to 0 nor ICMPv6 proxy: socket: permission denied\"\u001b[0m\n",
            "\u001b[90m2025-09-25T02:23:40Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Cannot determine default origin certificate path. No file cert.pem in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]. You need to specify the origin certificate path by specifying the origincert option in the configuration file, or set TUNNEL_ORIGIN_CERT environment variable \u001b[36moriginCertPath=\u001b[0m\n",
            "\u001b[90m2025-09-25T02:23:40Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.30.0.2 as source for IPv4\n",
            "\u001b[90m2025-09-25T02:23:40Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use fe80::c75:f9ff:fe41:b838 in zone eth0 as source for IPv6\n",
            "\u001b[90m2025-09-25T02:23:40Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n",
            "\u001b[90m2025-09-25T02:23:40Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel connection curve preferences: [X25519MLKEM768 CurveP256] \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.7\n",
            "2025/09/25 02:23:40 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "\u001b[90m2025-09-25T02:23:40Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0m2665d9f1-38c4-4195-9f93-27939cda8d46 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.7 \u001b[36mlocation=\u001b[0msea01 \u001b[36mprotocol=\u001b[0mquic\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "INFO:     2800:150:125:1a1c:1ca3:988d:9b93:e778:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "\u001b[90m2025-09-25T04:10:13Z\u001b[0m \u001b[32mINF\u001b[0m Initiating graceful shutdown due to signal interrupt ...\n",
            "\u001b[90m2025-09-25T04:10:13Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m failed to run the datagram handler \u001b[31merror=\u001b[0m\u001b[31m\"context canceled\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.7\n",
            "\u001b[90m2025-09-25T04:10:13Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m failed to serve tunnel connection \u001b[31merror=\u001b[0m\u001b[31m\"accept stream listener encountered a failure while serving\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.7\n",
            "\u001b[90m2025-09-25T04:10:13Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Serve tunnel error \u001b[31merror=\u001b[0m\u001b[31m\"accept stream listener encountered a failure while serving\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.7\n",
            "\u001b[90m2025-09-25T04:10:13Z\u001b[0m \u001b[32mINF\u001b[0m Retrying connection in up to 1s \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.7\n",
            "\u001b[90m2025-09-25T04:10:13Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Connection terminated \u001b[36mconnIndex=\u001b[0m0\n",
            "\u001b[90m2025-09-25T04:10:13Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m no more connections active and exiting\n",
            "\u001b[90m2025-09-25T04:10:13Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel server stopped\n",
            "\u001b[90m2025-09-25T04:10:13Z\u001b[0m \u001b[32mINF\u001b[0m Metrics server stopped\n"
          ]
        }
      ],
      "source": [
        "!cloudflared tunnel --url http://127.0.0.1:8000 --no-autoupdate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIN5pCI6LsMY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "runtime_attributes": {
        "runtime_version": "2025.07"
      }
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
